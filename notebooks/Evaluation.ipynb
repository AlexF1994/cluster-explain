{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e49caa39-7d0a-45b2-99f0-60031ed20262",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47c92dc0-e51c-45ed-9fde-c040e3d2ad26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fottneal\\Documents\\code\\cluster-explain\\.venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from abc import ABC, abstractmethod \n",
    "import random\n",
    "from numba import njit\n",
    "from numba.experimental import jitclass\n",
    "from numba import int32, float64\n",
    "from sklearn import datasets\n",
    "import mpl_toolkits.mplot3d \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cxplain.xkm import XkmExplainer\n",
    "from cxplain.tree import  DecisionTreeExplainer, RandomForestExplainer, ExKMCExplainer\n",
    "from cxplain.shap import  ShapExplainer\n",
    "from cxplain.gradient import GradientExplainer  \n",
    "from cxplain.metrics import EuclideanMetric, Metric, ManhattenMetric\n",
    "from cxplain.neon import NeonKMeansExplainer\n",
    "from cxplain.errors import NonExistingRelevanceError\n",
    "from imputer import NormalCKDEImputer, EmpiricalRandomImputer, get_imputer\n",
    "from datasets import IrisDataset, WineDataset, WholeSaleDataset, LiveSellersDataset, BuddyMoveDataset, SyntheticDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb9e41d-004a-4ae0-99cb-4496118b4e9a",
   "metadata": {},
   "source": [
    "Data sets to be considered:\n",
    "- https://archive-beta.ics.uci.edu/dataset/292/wholesale+customers\n",
    "- https://archive.ics.uci.edu/ml/datasets/BuddyMove+Data+Set# --> keine targets --> raus\n",
    "- https://archive.ics.uci.edu/ml/datasets/Facebook+Live+Sellers+in+Thailand#\n",
    "- https://archive.ics.uci.edu/ml/datasets/wine / https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine, included in scikit learn\n",
    "- https://www.researchgate.net/publication/331616284_A_morphological_database_for_Colombian_anuran_species_from_conservation-priority_ecosystems\n",
    "- https://archive.ics.uci.edu/ml/datasets/clickstream+data+for+online+shopping#\n",
    "- https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3edb4ddf-2f38-47f3-972d-f98c5551ad47",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\"iris\": IrisDataset.load_and_clean_dataset(),\n",
    "            \"wine\": WineDataset.load_and_clean_dataset(),\n",
    "            \"wholesale\": WholeSaleDataset.load_and_clean_dataset(\"../data/Wholesale customers data.csv\"),\n",
    "            \"buddy\": BuddyMoveDataset.load_and_clean_dataset(3, \"../data/buddymove_holidayiq.csv\"),\n",
    "            \"synthetic\": SyntheticDataset.load_and_clean_dataset(15, \"../data/data_s1.txt\"),\n",
    "            \"live_sellers\": LiveSellersDataset.load_and_clean_dataset(\"../data/Live_20210128.csv\")\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcd1a507-2f46-4cc7-ae16-70576d97b5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris\n",
      "trial: 1\n",
      "trial: 2\n",
      "trial: 3\n",
      "trial: 4\n",
      "trial: 5\n",
      "trial: 6\n",
      "trial: 7\n",
      "trial: 8\n",
      "trial: 9\n",
      "trial: 10\n",
      "trial: 11\n",
      "trial: 12\n",
      "trial: 13\n",
      "trial: 14\n",
      "trial: 15\n",
      "trial: 16\n",
      "trial: 17\n",
      "trial: 18\n",
      "trial: 19\n",
      "trial: 20\n",
      "trial: 21\n",
      "trial: 22\n",
      "trial: 23\n",
      "trial: 24\n",
      "trial: 25\n",
      "trial: 26\n",
      "trial: 27\n",
      "trial: 28\n",
      "trial: 29\n",
      "trial: 30\n",
      "trial: 31\n",
      "trial: 32\n",
      "trial: 33\n",
      "trial: 34\n",
      "trial: 35\n",
      "trial: 36\n",
      "trial: 37\n",
      "trial: 38\n",
      "trial: 39\n",
      "trial: 40\n",
      "trial: 41\n",
      "trial: 42\n",
      "trial: 43\n",
      "trial: 44\n",
      "trial: 45\n",
      "trial: 46\n",
      "trial: 47\n",
      "trial: 48\n",
      "trial: 49\n",
      "trial: 50\n",
      "trial: 51\n",
      "trial: 52\n",
      "trial: 53\n",
      "trial: 54\n",
      "trial: 55\n",
      "trial: 56\n",
      "trial: 57\n",
      "trial: 58\n",
      "trial: 59\n",
      "trial: 60\n",
      "trial: 61\n",
      "trial: 62\n",
      "trial: 63\n",
      "trial: 64\n",
      "trial: 65\n",
      "trial: 66\n",
      "trial: 67\n",
      "trial: 68\n",
      "trial: 69\n",
      "trial: 70\n",
      "trial: 71\n",
      "trial: 72\n",
      "trial: 73\n",
      "trial: 74\n",
      "trial: 75\n",
      "trial: 76\n",
      "trial: 77\n",
      "trial: 78\n",
      "trial: 79\n",
      "trial: 80\n",
      "trial: 81\n",
      "trial: 82\n",
      "trial: 83\n",
      "trial: 84\n",
      "trial: 85\n",
      "trial: 86\n",
      "trial: 87\n",
      "trial: 88\n",
      "trial: 89\n",
      "trial: 90\n",
      "trial: 91\n",
      "trial: 92\n",
      "trial: 93\n",
      "trial: 94\n",
      "trial: 95\n",
      "trial: 96\n",
      "trial: 97\n",
      "trial: 98\n",
      "trial: 99\n",
      "trial: 100\n",
      "wine\n",
      "trial: 1\n",
      "trial: 2\n",
      "trial: 3\n",
      "trial: 4\n",
      "trial: 5\n",
      "trial: 6\n",
      "trial: 7\n",
      "trial: 8\n",
      "trial: 9\n",
      "trial: 10\n",
      "trial: 11\n",
      "trial: 12\n",
      "trial: 13\n",
      "trial: 14\n",
      "trial: 15\n",
      "trial: 16\n",
      "trial: 17\n",
      "trial: 18\n",
      "trial: 19\n",
      "trial: 20\n",
      "trial: 21\n",
      "trial: 22\n",
      "trial: 23\n",
      "trial: 24\n",
      "trial: 25\n",
      "trial: 26\n",
      "trial: 27\n",
      "trial: 28\n",
      "trial: 29\n",
      "trial: 30\n",
      "trial: 31\n",
      "trial: 32\n",
      "trial: 33\n",
      "trial: 34\n",
      "trial: 35\n",
      "trial: 36\n",
      "trial: 37\n",
      "trial: 38\n",
      "trial: 39\n",
      "trial: 40\n",
      "trial: 41\n",
      "trial: 42\n",
      "trial: 43\n",
      "trial: 44\n",
      "trial: 45\n",
      "trial: 46\n",
      "trial: 47\n",
      "trial: 48\n",
      "trial: 49\n",
      "trial: 50\n",
      "trial: 51\n",
      "trial: 52\n",
      "trial: 53\n",
      "trial: 54\n",
      "trial: 55\n",
      "trial: 56\n",
      "trial: 57\n",
      "trial: 58\n",
      "trial: 59\n",
      "trial: 60\n",
      "trial: 61\n",
      "trial: 62\n",
      "trial: 63\n",
      "trial: 64\n",
      "trial: 65\n",
      "trial: 66\n",
      "trial: 67\n",
      "trial: 68\n",
      "trial: 69\n",
      "trial: 70\n",
      "trial: 71\n",
      "trial: 72\n",
      "trial: 73\n",
      "trial: 74\n",
      "trial: 75\n",
      "trial: 76\n",
      "trial: 77\n",
      "trial: 78\n",
      "trial: 79\n",
      "trial: 80\n",
      "trial: 81\n",
      "trial: 82\n",
      "trial: 83\n",
      "trial: 84\n",
      "trial: 85\n",
      "trial: 86\n",
      "trial: 87\n",
      "trial: 88\n",
      "trial: 89\n",
      "trial: 90\n",
      "trial: 91\n",
      "trial: 92\n",
      "trial: 93\n",
      "trial: 94\n",
      "trial: 95\n",
      "trial: 96\n",
      "trial: 97\n",
      "trial: 98\n",
      "trial: 99\n",
      "trial: 100\n",
      "wholesale\n",
      "trial: 1\n",
      "trial: 2\n",
      "trial: 3\n",
      "trial: 4\n",
      "trial: 5\n",
      "trial: 6\n",
      "trial: 7\n",
      "trial: 8\n",
      "trial: 9\n",
      "trial: 10\n",
      "trial: 11\n",
      "trial: 12\n",
      "trial: 13\n",
      "trial: 14\n",
      "trial: 15\n",
      "trial: 16\n",
      "trial: 17\n",
      "trial: 18\n",
      "trial: 19\n",
      "trial: 20\n",
      "trial: 21\n",
      "trial: 22\n",
      "trial: 23\n",
      "trial: 24\n",
      "trial: 25\n",
      "trial: 26\n",
      "trial: 27\n",
      "trial: 28\n",
      "trial: 29\n",
      "trial: 30\n",
      "trial: 31\n",
      "trial: 32\n",
      "trial: 33\n",
      "trial: 34\n",
      "trial: 35\n",
      "trial: 36\n",
      "trial: 37\n",
      "trial: 38\n",
      "trial: 39\n",
      "trial: 40\n",
      "trial: 41\n",
      "trial: 42\n",
      "trial: 43\n",
      "trial: 44\n",
      "trial: 45\n",
      "trial: 46\n",
      "trial: 47\n",
      "trial: 48\n",
      "trial: 49\n",
      "trial: 50\n",
      "trial: 51\n",
      "trial: 52\n",
      "trial: 53\n",
      "trial: 54\n",
      "trial: 55\n",
      "trial: 56\n",
      "trial: 57\n",
      "trial: 58\n",
      "trial: 59\n",
      "trial: 60\n",
      "trial: 61\n",
      "trial: 62\n",
      "trial: 63\n",
      "trial: 64\n",
      "trial: 65\n",
      "trial: 66\n",
      "trial: 67\n",
      "trial: 68\n",
      "trial: 69\n",
      "trial: 70\n",
      "trial: 71\n",
      "trial: 72\n",
      "trial: 73\n",
      "trial: 74\n",
      "trial: 75\n",
      "trial: 76\n",
      "trial: 77\n",
      "trial: 78\n",
      "trial: 79\n",
      "trial: 80\n",
      "trial: 81\n",
      "trial: 82\n",
      "trial: 83\n",
      "trial: 84\n",
      "trial: 85\n",
      "trial: 86\n",
      "trial: 87\n",
      "trial: 88\n",
      "trial: 89\n",
      "trial: 90\n",
      "trial: 91\n",
      "trial: 92\n",
      "trial: 93\n",
      "trial: 94\n",
      "trial: 95\n",
      "trial: 96\n",
      "trial: 97\n",
      "trial: 98\n",
      "trial: 99\n",
      "trial: 100\n",
      "buddy\n",
      "trial: 1\n",
      "trial: 2\n",
      "trial: 3\n",
      "trial: 4\n",
      "trial: 5\n",
      "trial: 6\n",
      "trial: 7\n",
      "trial: 8\n",
      "trial: 9\n",
      "trial: 10\n",
      "trial: 11\n",
      "trial: 12\n",
      "trial: 13\n",
      "trial: 14\n",
      "trial: 15\n",
      "trial: 16\n",
      "trial: 17\n",
      "trial: 18\n",
      "trial: 19\n",
      "trial: 20\n",
      "trial: 21\n",
      "trial: 22\n",
      "trial: 23\n",
      "trial: 24\n",
      "trial: 25\n",
      "trial: 26\n",
      "trial: 27\n",
      "trial: 28\n",
      "trial: 29\n",
      "trial: 30\n",
      "trial: 31\n",
      "trial: 32\n",
      "trial: 33\n",
      "trial: 34\n",
      "trial: 35\n",
      "trial: 36\n",
      "trial: 37\n",
      "trial: 38\n",
      "trial: 39\n",
      "trial: 40\n",
      "trial: 41\n",
      "trial: 42\n",
      "trial: 43\n",
      "trial: 44\n",
      "trial: 45\n",
      "trial: 46\n",
      "trial: 47\n",
      "trial: 48\n",
      "trial: 49\n",
      "trial: 50\n",
      "trial: 51\n",
      "trial: 52\n",
      "trial: 53\n",
      "trial: 54\n",
      "trial: 55\n",
      "trial: 56\n",
      "trial: 57\n",
      "trial: 58\n",
      "trial: 59\n",
      "trial: 60\n",
      "trial: 61\n",
      "trial: 62\n",
      "trial: 63\n",
      "trial: 64\n",
      "trial: 65\n",
      "trial: 66\n",
      "trial: 67\n",
      "trial: 68\n",
      "trial: 69\n",
      "trial: 70\n",
      "trial: 71\n",
      "trial: 72\n",
      "trial: 73\n",
      "trial: 74\n",
      "trial: 75\n",
      "trial: 76\n",
      "trial: 77\n",
      "trial: 78\n",
      "trial: 79\n",
      "trial: 80\n",
      "trial: 81\n",
      "trial: 82\n",
      "trial: 83\n",
      "trial: 84\n",
      "trial: 85\n",
      "trial: 86\n",
      "trial: 87\n",
      "trial: 88\n",
      "trial: 89\n",
      "trial: 90\n",
      "trial: 91\n",
      "trial: 92\n",
      "trial: 93\n",
      "trial: 94\n",
      "trial: 95\n",
      "trial: 96\n",
      "trial: 97\n",
      "trial: 98\n",
      "trial: 99\n",
      "trial: 100\n",
      "synthetic\n",
      "trial: 1\n",
      "trial: 2\n",
      "trial: 3\n",
      "trial: 4\n",
      "trial: 5\n",
      "trial: 6\n",
      "trial: 7\n",
      "trial: 8\n",
      "trial: 9\n",
      "trial: 10\n",
      "trial: 11\n",
      "trial: 12\n",
      "trial: 13\n",
      "trial: 14\n",
      "trial: 15\n",
      "trial: 16\n",
      "trial: 17\n",
      "trial: 18\n",
      "trial: 19\n",
      "trial: 20\n",
      "trial: 21\n",
      "trial: 22\n",
      "trial: 23\n",
      "trial: 24\n",
      "trial: 25\n",
      "trial: 26\n",
      "trial: 27\n",
      "trial: 28\n",
      "trial: 29\n",
      "trial: 30\n",
      "trial: 31\n",
      "trial: 32\n",
      "trial: 33\n",
      "trial: 34\n",
      "trial: 35\n",
      "trial: 36\n",
      "trial: 37\n",
      "trial: 38\n",
      "trial: 39\n",
      "trial: 40\n",
      "trial: 41\n",
      "trial: 42\n",
      "trial: 43\n",
      "trial: 44\n",
      "trial: 45\n",
      "trial: 46\n",
      "trial: 47\n",
      "trial: 48\n",
      "trial: 49\n",
      "trial: 50\n",
      "trial: 51\n",
      "trial: 52\n",
      "trial: 53\n",
      "trial: 54\n",
      "trial: 55\n",
      "trial: 56\n",
      "trial: 57\n",
      "trial: 58\n",
      "trial: 59\n",
      "trial: 60\n",
      "trial: 61\n",
      "trial: 62\n",
      "trial: 63\n",
      "trial: 64\n",
      "trial: 65\n",
      "trial: 66\n",
      "trial: 67\n",
      "trial: 68\n",
      "trial: 69\n",
      "trial: 70\n",
      "trial: 71\n",
      "trial: 72\n",
      "trial: 73\n",
      "trial: 74\n",
      "trial: 75\n",
      "trial: 76\n",
      "trial: 77\n",
      "trial: 78\n",
      "trial: 79\n",
      "trial: 80\n",
      "trial: 81\n",
      "trial: 82\n",
      "trial: 83\n",
      "trial: 84\n",
      "trial: 85\n",
      "trial: 86\n",
      "trial: 87\n",
      "trial: 88\n",
      "trial: 89\n",
      "trial: 90\n",
      "trial: 91\n",
      "trial: 92\n",
      "trial: 93\n",
      "trial: 94\n",
      "trial: 95\n",
      "trial: 96\n",
      "trial: 97\n",
      "trial: 98\n",
      "trial: 99\n",
      "trial: 100\n",
      "live_sellers\n",
      "trial: 1\n",
      "trial: 2\n",
      "trial: 3\n",
      "trial: 4\n",
      "trial: 5\n",
      "trial: 6\n",
      "trial: 7\n",
      "trial: 8\n",
      "trial: 9\n",
      "trial: 10\n",
      "trial: 11\n",
      "trial: 12\n",
      "trial: 13\n",
      "trial: 14\n",
      "trial: 15\n",
      "trial: 16\n",
      "trial: 17\n",
      "trial: 18\n",
      "trial: 19\n",
      "trial: 20\n",
      "trial: 21\n",
      "trial: 22\n",
      "trial: 23\n",
      "trial: 24\n",
      "trial: 25\n",
      "trial: 26\n",
      "trial: 27\n",
      "trial: 28\n",
      "trial: 29\n",
      "trial: 30\n",
      "trial: 31\n",
      "trial: 32\n",
      "trial: 33\n",
      "trial: 34\n",
      "trial: 35\n",
      "trial: 36\n",
      "trial: 37\n",
      "trial: 38\n",
      "trial: 39\n",
      "trial: 40\n",
      "trial: 41\n",
      "trial: 42\n",
      "trial: 43\n",
      "trial: 44\n",
      "trial: 45\n",
      "trial: 46\n",
      "trial: 47\n",
      "trial: 48\n",
      "trial: 49\n",
      "trial: 50\n",
      "trial: 51\n",
      "trial: 52\n",
      "trial: 53\n",
      "trial: 54\n",
      "trial: 55\n",
      "trial: 56\n",
      "trial: 57\n",
      "trial: 58\n",
      "trial: 59\n",
      "trial: 60\n",
      "trial: 61\n",
      "trial: 62\n",
      "trial: 63\n",
      "trial: 64\n",
      "trial: 65\n",
      "trial: 66\n",
      "trial: 67\n",
      "trial: 68\n",
      "trial: 69\n",
      "trial: 70\n",
      "trial: 71\n",
      "trial: 72\n",
      "trial: 73\n",
      "trial: 74\n",
      "trial: 75\n",
      "trial: 76\n",
      "trial: 77\n",
      "trial: 78\n",
      "trial: 79\n",
      "trial: 80\n",
      "trial: 81\n",
      "trial: 82\n",
      "trial: 83\n",
      "trial: 84\n",
      "trial: 85\n",
      "trial: 86\n",
      "trial: 87\n",
      "trial: 88\n",
      "trial: 89\n",
      "trial: 90\n",
      "trial: 91\n",
      "trial: 92\n",
      "trial: 93\n",
      "trial: 94\n",
      "trial: 95\n",
      "trial: 96\n",
      "trial: 97\n",
      "trial: 98\n",
      "trial: 99\n",
      "trial: 100\n"
     ]
    }
   ],
   "source": [
    "only_global = False\n",
    "use_imputer = True\n",
    "imputer_name = \"random\"\n",
    "n_trials = 100\n",
    "\n",
    "#np.random.seed(3)\n",
    "\n",
    "dataset_results_local = {}\n",
    "\n",
    "for dataset_name, dataset in datasets.items():\n",
    "    print(dataset_name)\n",
    "\n",
    "    n_clusters = dataset.n_clusters\n",
    "    X = dataset.features\n",
    "    y = dataset.targets\n",
    "    n_obs = dataset.n_obs\n",
    "    n_features = dataset.n_features\n",
    "\n",
    "    # fit Kmeans\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=3).fit(X)\n",
    "    cluster_centers = kmeans.cluster_centers_\n",
    "    predictions = kmeans.predict(X)\n",
    "    # init and fit explainer\n",
    "    # list allexplainers\n",
    "    explainers = {\"tree\": DecisionTreeExplainer(data= X, cluster_predictions=predictions),\n",
    "                 \"forest\": RandomForestExplainer(data= X, cluster_predictions=predictions),\n",
    "                 \"exkmc\": ExKMCExplainer(X, kmeans, k=n_clusters, max_leaves=2*n_clusters),\n",
    "                 \"gradient\": GradientExplainer(X, cluster_centers, predictions, EuclideanMetric, enable_abs_calculation=False),\n",
    "                 \"shap\": ShapExplainer(data= X, cluster_predictions=predictions),\n",
    "                 \"neon\": NeonKMeansExplainer(cluster_centers=cluster_centers, data=X, predictions=predictions),\n",
    "                 \"xkm_next_best\": XkmExplainer(X,  kmeans.cluster_centers_, \"next_best\", \"euclidean\", predictions),\n",
    "                 \"xkm_all\": XkmExplainer(X,  kmeans.cluster_centers_, \"all\", \"euclidean\", predictions)}\n",
    "\n",
    "    # fit and explain all explainers\n",
    "\n",
    "    explanations = {explainer_name:explainer.fit_explain() for explainer_name, explainer  in explainers.items()}\n",
    "\n",
    "    # first calculate all ROC curves for individual observations\n",
    "    result_individual = {explainer_name: [] for explainer_name in explanations.keys()}\n",
    "    if use_imputer:\n",
    "        imputer = get_imputer(imputer_name)(X).fit()\n",
    "    for _ in range(n_trials):\n",
    "        print(f\"trial: {_ + 1}\")\n",
    "        for explainer_name, explanation in explanations.items():\n",
    "            # init curve_list\n",
    "            curve_list = []\n",
    "            for index_obs in range(n_obs):\n",
    "                # init list curve_obs_i to all 1 (length = num_features)\n",
    "                curve_obs = [1 for i in range(n_features)]\n",
    "                # init array of feature observations, I use an array instead of a list, as it is easier  later on to calculate distances to cluster centers\n",
    "                feature_obs = np.array([0.0 for i in range(n_features)])\n",
    "                # get relevance scores for observation, for explainers with only global scores, these will be used for every observation\n",
    "                if only_global:\n",
    "                    relevance_scores = list(explanations[explainer_name].global_relevance)\n",
    "                else:\n",
    "                    try:\n",
    "                        relevance_scores = list(explanations[explainer_name].pointwise_relevance.iloc[index_obs, :])\n",
    "                    except NonExistingRelevanceError:\n",
    "                        relevance_scores = list(explanations[explainer_name].global_relevance)\n",
    "\n",
    "                for feature_index in range(n_features):\n",
    "                    # get biggest score and column index (indicate which feature is meant) and pop from list\n",
    "                    index_biggest_score = relevance_scores.index(max(relevance_scores))                \n",
    "                    relevance_scores[index_biggest_score] = -1000 # I set to large negative number as popping would ruin the index correspondence from relevance score to feature\n",
    "                    # get observation for this feature\n",
    "                    obs_biggest_score = X[index_obs, index_biggest_score]\n",
    "                    # get corresponding cluster index for this observation\n",
    "                    cluster_index = predictions[index_obs]\n",
    "                    # add observation for feature to feature observations list\n",
    "                    feature_obs.put(index_biggest_score, obs_biggest_score) # has to be at index of feature in training data, as otherwise distance calculation is wrong\n",
    "                    # impute other entries (length = num_features) --> TBD\n",
    "                    if use_imputer: \n",
    "                        if feature_index < (n_features - 1):\n",
    "                            feature_obs_imputed = imputer.predict(feature_obs, index_obs)\n",
    "                        else:\n",
    "                            feature_obs_imputed = feature_obs.copy()\n",
    "                    else:\n",
    "                        feature_obs_imputed = feature_obs.copy()\n",
    "                    # calculate distance to cluster centers for feature observations list\n",
    "                    distances = [np.linalg.norm(feature_obs_imputed - center) for center in cluster_centers]\n",
    "                    # get nearest_cluster_index\n",
    "                    nearest_cluster_index = distances.index(min(distances))\n",
    "                    # check whether cluster_index == nearest_cluster_index\n",
    "                    # if yes: return curve_obs_i\n",
    "                    # if no: replace first entry of curve_obs_i ith 0 and repeat\n",
    "                    if cluster_index == nearest_cluster_index:\n",
    "                        break\n",
    "                    else:\n",
    "                        curve_obs[feature_index] = 0\n",
    "                    # if yes: return curve_obs_i\n",
    "                    # if no: replace first entry of curve_obs_i ith 0 and repeat\n",
    "\n",
    "                curve_list.append(curve_obs)\n",
    "\n",
    "            # add explainer entry to dict\n",
    "            result_individual[explainer_name].extend(curve_list)\n",
    "\n",
    "    # Now compute AUC\n",
    "    result_auc = {explainer_name: (1 /(n_obs*n_features*n_trials)) * sum(map(sum, curves)) for explainer_name, curves in result_individual.items()}\n",
    "\n",
    "    dataset_results_local[dataset_name] = result_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dac639e1-4d2b-4077-94cf-a9f23d8bbddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris\n",
      "trial: 1\n",
      "trial: 2\n",
      "trial: 3\n",
      "trial: 4\n",
      "trial: 5\n",
      "trial: 6\n",
      "trial: 7\n",
      "trial: 8\n",
      "trial: 9\n",
      "trial: 10\n",
      "trial: 11\n",
      "trial: 12\n",
      "trial: 13\n",
      "trial: 14\n",
      "trial: 15\n",
      "trial: 16\n",
      "trial: 17\n",
      "trial: 18\n",
      "trial: 19\n",
      "trial: 20\n",
      "trial: 21\n",
      "trial: 22\n",
      "trial: 23\n",
      "trial: 24\n",
      "trial: 25\n",
      "trial: 26\n",
      "trial: 27\n",
      "trial: 28\n",
      "trial: 29\n",
      "trial: 30\n",
      "trial: 31\n",
      "trial: 32\n",
      "trial: 33\n",
      "trial: 34\n",
      "trial: 35\n",
      "trial: 36\n",
      "trial: 37\n",
      "trial: 38\n",
      "trial: 39\n",
      "trial: 40\n",
      "trial: 41\n",
      "trial: 42\n",
      "trial: 43\n",
      "trial: 44\n",
      "trial: 45\n",
      "trial: 46\n",
      "trial: 47\n",
      "trial: 48\n",
      "trial: 49\n",
      "trial: 50\n",
      "trial: 51\n",
      "trial: 52\n",
      "trial: 53\n",
      "trial: 54\n",
      "trial: 55\n",
      "trial: 56\n",
      "trial: 57\n",
      "trial: 58\n",
      "trial: 59\n",
      "trial: 60\n",
      "trial: 61\n",
      "trial: 62\n",
      "trial: 63\n",
      "trial: 64\n",
      "trial: 65\n",
      "trial: 66\n",
      "trial: 67\n",
      "trial: 68\n",
      "trial: 69\n",
      "trial: 70\n",
      "trial: 71\n",
      "trial: 72\n",
      "trial: 73\n",
      "trial: 74\n",
      "trial: 75\n",
      "trial: 76\n",
      "trial: 77\n",
      "trial: 78\n",
      "trial: 79\n",
      "trial: 80\n",
      "trial: 81\n",
      "trial: 82\n",
      "trial: 83\n",
      "trial: 84\n",
      "trial: 85\n",
      "trial: 86\n",
      "trial: 87\n",
      "trial: 88\n",
      "trial: 89\n",
      "trial: 90\n",
      "trial: 91\n",
      "trial: 92\n",
      "trial: 93\n",
      "trial: 94\n",
      "trial: 95\n",
      "trial: 96\n",
      "trial: 97\n",
      "trial: 98\n",
      "trial: 99\n",
      "trial: 100\n",
      "wine\n",
      "trial: 1\n",
      "trial: 2\n",
      "trial: 3\n",
      "trial: 4\n",
      "trial: 5\n",
      "trial: 6\n",
      "trial: 7\n",
      "trial: 8\n",
      "trial: 9\n",
      "trial: 10\n",
      "trial: 11\n",
      "trial: 12\n",
      "trial: 13\n",
      "trial: 14\n",
      "trial: 15\n",
      "trial: 16\n",
      "trial: 17\n",
      "trial: 18\n",
      "trial: 19\n",
      "trial: 20\n",
      "trial: 21\n",
      "trial: 22\n",
      "trial: 23\n",
      "trial: 24\n",
      "trial: 25\n",
      "trial: 26\n",
      "trial: 27\n",
      "trial: 28\n",
      "trial: 29\n",
      "trial: 30\n",
      "trial: 31\n",
      "trial: 32\n",
      "trial: 33\n",
      "trial: 34\n",
      "trial: 35\n",
      "trial: 36\n",
      "trial: 37\n",
      "trial: 38\n",
      "trial: 39\n",
      "trial: 40\n",
      "trial: 41\n",
      "trial: 42\n",
      "trial: 43\n",
      "trial: 44\n",
      "trial: 45\n",
      "trial: 46\n",
      "trial: 47\n",
      "trial: 48\n",
      "trial: 49\n",
      "trial: 50\n",
      "trial: 51\n",
      "trial: 52\n",
      "trial: 53\n",
      "trial: 54\n",
      "trial: 55\n",
      "trial: 56\n",
      "trial: 57\n",
      "trial: 58\n",
      "trial: 59\n",
      "trial: 60\n",
      "trial: 61\n",
      "trial: 62\n",
      "trial: 63\n",
      "trial: 64\n",
      "trial: 65\n",
      "trial: 66\n",
      "trial: 67\n",
      "trial: 68\n",
      "trial: 69\n",
      "trial: 70\n",
      "trial: 71\n",
      "trial: 72\n",
      "trial: 73\n",
      "trial: 74\n",
      "trial: 75\n",
      "trial: 76\n",
      "trial: 77\n",
      "trial: 78\n",
      "trial: 79\n",
      "trial: 80\n",
      "trial: 81\n",
      "trial: 82\n",
      "trial: 83\n",
      "trial: 84\n",
      "trial: 85\n",
      "trial: 86\n",
      "trial: 87\n",
      "trial: 88\n",
      "trial: 89\n",
      "trial: 90\n",
      "trial: 91\n",
      "trial: 92\n",
      "trial: 93\n",
      "trial: 94\n",
      "trial: 95\n",
      "trial: 96\n",
      "trial: 97\n",
      "trial: 98\n",
      "trial: 99\n",
      "trial: 100\n",
      "wholesale\n",
      "trial: 1\n",
      "trial: 2\n",
      "trial: 3\n",
      "trial: 4\n",
      "trial: 5\n",
      "trial: 6\n",
      "trial: 7\n",
      "trial: 8\n",
      "trial: 9\n",
      "trial: 10\n",
      "trial: 11\n",
      "trial: 12\n",
      "trial: 13\n",
      "trial: 14\n",
      "trial: 15\n",
      "trial: 16\n",
      "trial: 17\n",
      "trial: 18\n",
      "trial: 19\n",
      "trial: 20\n",
      "trial: 21\n",
      "trial: 22\n",
      "trial: 23\n",
      "trial: 24\n",
      "trial: 25\n",
      "trial: 26\n",
      "trial: 27\n",
      "trial: 28\n",
      "trial: 29\n",
      "trial: 30\n",
      "trial: 31\n",
      "trial: 32\n",
      "trial: 33\n",
      "trial: 34\n",
      "trial: 35\n",
      "trial: 36\n",
      "trial: 37\n",
      "trial: 38\n",
      "trial: 39\n",
      "trial: 40\n",
      "trial: 41\n",
      "trial: 42\n",
      "trial: 43\n",
      "trial: 44\n",
      "trial: 45\n",
      "trial: 46\n",
      "trial: 47\n",
      "trial: 48\n",
      "trial: 49\n",
      "trial: 50\n",
      "trial: 51\n",
      "trial: 52\n",
      "trial: 53\n",
      "trial: 54\n",
      "trial: 55\n",
      "trial: 56\n",
      "trial: 57\n",
      "trial: 58\n",
      "trial: 59\n",
      "trial: 60\n",
      "trial: 61\n",
      "trial: 62\n",
      "trial: 63\n",
      "trial: 64\n",
      "trial: 65\n",
      "trial: 66\n",
      "trial: 67\n",
      "trial: 68\n",
      "trial: 69\n",
      "trial: 70\n",
      "trial: 71\n",
      "trial: 72\n",
      "trial: 73\n",
      "trial: 74\n",
      "trial: 75\n",
      "trial: 76\n",
      "trial: 77\n",
      "trial: 78\n",
      "trial: 79\n",
      "trial: 80\n",
      "trial: 81\n",
      "trial: 82\n",
      "trial: 83\n",
      "trial: 84\n",
      "trial: 85\n",
      "trial: 86\n",
      "trial: 87\n",
      "trial: 88\n",
      "trial: 89\n",
      "trial: 90\n",
      "trial: 91\n",
      "trial: 92\n",
      "trial: 93\n",
      "trial: 94\n",
      "trial: 95\n",
      "trial: 96\n",
      "trial: 97\n",
      "trial: 98\n",
      "trial: 99\n",
      "trial: 100\n",
      "buddy\n",
      "trial: 1\n",
      "trial: 2\n",
      "trial: 3\n",
      "trial: 4\n",
      "trial: 5\n",
      "trial: 6\n",
      "trial: 7\n",
      "trial: 8\n",
      "trial: 9\n",
      "trial: 10\n",
      "trial: 11\n",
      "trial: 12\n",
      "trial: 13\n",
      "trial: 14\n",
      "trial: 15\n",
      "trial: 16\n",
      "trial: 17\n",
      "trial: 18\n",
      "trial: 19\n",
      "trial: 20\n",
      "trial: 21\n",
      "trial: 22\n",
      "trial: 23\n",
      "trial: 24\n",
      "trial: 25\n",
      "trial: 26\n",
      "trial: 27\n",
      "trial: 28\n",
      "trial: 29\n",
      "trial: 30\n",
      "trial: 31\n",
      "trial: 32\n",
      "trial: 33\n",
      "trial: 34\n",
      "trial: 35\n",
      "trial: 36\n",
      "trial: 37\n",
      "trial: 38\n",
      "trial: 39\n",
      "trial: 40\n",
      "trial: 41\n",
      "trial: 42\n",
      "trial: 43\n",
      "trial: 44\n",
      "trial: 45\n",
      "trial: 46\n",
      "trial: 47\n",
      "trial: 48\n",
      "trial: 49\n",
      "trial: 50\n",
      "trial: 51\n",
      "trial: 52\n",
      "trial: 53\n",
      "trial: 54\n",
      "trial: 55\n",
      "trial: 56\n",
      "trial: 57\n",
      "trial: 58\n",
      "trial: 59\n",
      "trial: 60\n",
      "trial: 61\n",
      "trial: 62\n",
      "trial: 63\n",
      "trial: 64\n",
      "trial: 65\n",
      "trial: 66\n",
      "trial: 67\n",
      "trial: 68\n",
      "trial: 69\n",
      "trial: 70\n",
      "trial: 71\n",
      "trial: 72\n",
      "trial: 73\n",
      "trial: 74\n",
      "trial: 75\n",
      "trial: 76\n",
      "trial: 77\n",
      "trial: 78\n",
      "trial: 79\n",
      "trial: 80\n",
      "trial: 81\n",
      "trial: 82\n",
      "trial: 83\n",
      "trial: 84\n",
      "trial: 85\n",
      "trial: 86\n",
      "trial: 87\n",
      "trial: 88\n",
      "trial: 89\n",
      "trial: 90\n",
      "trial: 91\n",
      "trial: 92\n",
      "trial: 93\n",
      "trial: 94\n",
      "trial: 95\n",
      "trial: 96\n",
      "trial: 97\n",
      "trial: 98\n",
      "trial: 99\n",
      "trial: 100\n",
      "synthetic\n",
      "trial: 1\n",
      "trial: 2\n",
      "trial: 3\n",
      "trial: 4\n",
      "trial: 5\n",
      "trial: 6\n",
      "trial: 7\n",
      "trial: 8\n",
      "trial: 9\n",
      "trial: 10\n",
      "trial: 11\n",
      "trial: 12\n",
      "trial: 13\n",
      "trial: 14\n",
      "trial: 15\n",
      "trial: 16\n",
      "trial: 17\n",
      "trial: 18\n",
      "trial: 19\n",
      "trial: 20\n",
      "trial: 21\n",
      "trial: 22\n",
      "trial: 23\n",
      "trial: 24\n",
      "trial: 25\n",
      "trial: 26\n",
      "trial: 27\n",
      "trial: 28\n",
      "trial: 29\n",
      "trial: 30\n",
      "trial: 31\n",
      "trial: 32\n",
      "trial: 33\n",
      "trial: 34\n",
      "trial: 35\n",
      "trial: 36\n",
      "trial: 37\n",
      "trial: 38\n",
      "trial: 39\n",
      "trial: 40\n",
      "trial: 41\n",
      "trial: 42\n",
      "trial: 43\n",
      "trial: 44\n",
      "trial: 45\n",
      "trial: 46\n",
      "trial: 47\n",
      "trial: 48\n",
      "trial: 49\n",
      "trial: 50\n",
      "trial: 51\n",
      "trial: 52\n",
      "trial: 53\n",
      "trial: 54\n",
      "trial: 55\n",
      "trial: 56\n",
      "trial: 57\n",
      "trial: 58\n",
      "trial: 59\n",
      "trial: 60\n",
      "trial: 61\n",
      "trial: 62\n",
      "trial: 63\n",
      "trial: 64\n",
      "trial: 65\n",
      "trial: 66\n",
      "trial: 67\n",
      "trial: 68\n",
      "trial: 69\n",
      "trial: 70\n",
      "trial: 71\n",
      "trial: 72\n",
      "trial: 73\n",
      "trial: 74\n",
      "trial: 75\n",
      "trial: 76\n",
      "trial: 77\n",
      "trial: 78\n",
      "trial: 79\n",
      "trial: 80\n",
      "trial: 81\n",
      "trial: 82\n",
      "trial: 83\n",
      "trial: 84\n",
      "trial: 85\n",
      "trial: 86\n",
      "trial: 87\n",
      "trial: 88\n",
      "trial: 89\n",
      "trial: 90\n",
      "trial: 91\n",
      "trial: 92\n",
      "trial: 93\n",
      "trial: 94\n",
      "trial: 95\n",
      "trial: 96\n",
      "trial: 97\n",
      "trial: 98\n",
      "trial: 99\n",
      "trial: 100\n",
      "live_sellers\n",
      "trial: 1\n",
      "trial: 2\n",
      "trial: 3\n",
      "trial: 4\n",
      "trial: 5\n",
      "trial: 6\n",
      "trial: 7\n",
      "trial: 8\n",
      "trial: 9\n",
      "trial: 10\n",
      "trial: 11\n",
      "trial: 12\n",
      "trial: 13\n",
      "trial: 14\n",
      "trial: 15\n",
      "trial: 16\n",
      "trial: 17\n",
      "trial: 18\n",
      "trial: 19\n",
      "trial: 20\n",
      "trial: 21\n",
      "trial: 22\n",
      "trial: 23\n",
      "trial: 24\n",
      "trial: 25\n",
      "trial: 26\n",
      "trial: 27\n",
      "trial: 28\n",
      "trial: 29\n",
      "trial: 30\n",
      "trial: 31\n",
      "trial: 32\n",
      "trial: 33\n",
      "trial: 34\n",
      "trial: 35\n",
      "trial: 36\n",
      "trial: 37\n",
      "trial: 38\n",
      "trial: 39\n",
      "trial: 40\n",
      "trial: 41\n",
      "trial: 42\n",
      "trial: 43\n",
      "trial: 44\n",
      "trial: 45\n",
      "trial: 46\n",
      "trial: 47\n",
      "trial: 48\n",
      "trial: 49\n",
      "trial: 50\n",
      "trial: 51\n",
      "trial: 52\n",
      "trial: 53\n",
      "trial: 54\n",
      "trial: 55\n",
      "trial: 56\n",
      "trial: 57\n",
      "trial: 58\n",
      "trial: 59\n",
      "trial: 60\n",
      "trial: 61\n",
      "trial: 62\n",
      "trial: 63\n",
      "trial: 64\n",
      "trial: 65\n",
      "trial: 66\n",
      "trial: 67\n",
      "trial: 68\n",
      "trial: 69\n",
      "trial: 70\n",
      "trial: 71\n",
      "trial: 72\n",
      "trial: 73\n",
      "trial: 74\n",
      "trial: 75\n",
      "trial: 76\n",
      "trial: 77\n",
      "trial: 78\n",
      "trial: 79\n",
      "trial: 80\n",
      "trial: 81\n",
      "trial: 82\n",
      "trial: 83\n",
      "trial: 84\n",
      "trial: 85\n",
      "trial: 86\n",
      "trial: 87\n",
      "trial: 88\n",
      "trial: 89\n",
      "trial: 90\n",
      "trial: 91\n",
      "trial: 92\n",
      "trial: 93\n",
      "trial: 94\n",
      "trial: 95\n",
      "trial: 96\n",
      "trial: 97\n",
      "trial: 98\n",
      "trial: 99\n",
      "trial: 100\n"
     ]
    }
   ],
   "source": [
    "only_global = True\n",
    "use_imputer = True\n",
    "imputer_name = \"random\"\n",
    "n_trials = 100\n",
    "\n",
    "#np.random.seed(3)\n",
    "dataset_results_global = {}\n",
    "\n",
    "for dataset_name, dataset in datasets.items():\n",
    "    print(dataset_name)\n",
    "\n",
    "    n_clusters = dataset.n_clusters\n",
    "    X = dataset.features\n",
    "    y = dataset.targets\n",
    "    n_obs = dataset.n_obs\n",
    "    n_features = dataset.n_features\n",
    "\n",
    "    # fit Kmeans\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=3).fit(X)\n",
    "    cluster_centers = kmeans.cluster_centers_\n",
    "    predictions = kmeans.predict(X)\n",
    "    # init and fit explainer\n",
    "    # list allexplainers\n",
    "    explainers = {\"tree\": DecisionTreeExplainer(data= X, cluster_predictions=predictions),\n",
    "                 \"forest\": RandomForestExplainer(data= X, cluster_predictions=predictions),\n",
    "                 \"exkmc\": ExKMCExplainer(X, kmeans, k=n_clusters, max_leaves=2*n_clusters),\n",
    "                 \"gradient\": GradientExplainer(X, cluster_centers, predictions, EuclideanMetric, enable_abs_calculation=False),\n",
    "                 \"shap\": ShapExplainer(data= X, cluster_predictions=predictions),\n",
    "                 \"neon\": NeonKMeansExplainer(cluster_centers=cluster_centers, data=X, predictions=predictions),\n",
    "                 \"xkm_next_best\": XkmExplainer(X,  kmeans.cluster_centers_, \"next_best\", \"euclidean\", predictions),\n",
    "                 \"xkm_all\": XkmExplainer(X,  kmeans.cluster_centers_, \"all\", \"euclidean\", predictions)}\n",
    "\n",
    "    # fit and explain all explainers\n",
    "\n",
    "    explanations = {explainer_name:explainer.fit_explain() for explainer_name, explainer  in explainers.items()}\n",
    "\n",
    "    # first calculate all ROC curves for individual observations\n",
    "    result_individual = {explainer_name: [] for explainer_name in explanations.keys()}\n",
    "    if use_imputer:\n",
    "        imputer = get_imputer(imputer_name)(X).fit()\n",
    "    for _ in range(n_trials):\n",
    "        print(f\"trial: {_ + 1}\")\n",
    "        for explainer_name, explanation in explanations.items():\n",
    "            # init curve_list\n",
    "            curve_list = []\n",
    "            for index_obs in range(n_obs):\n",
    "                # init list curve_obs_i to all 1 (length = num_features)\n",
    "                curve_obs = [1 for i in range(n_features)]\n",
    "                # init array of feature observations, I use an array instead of a list, as it is easier  later on to calculate distances to cluster centers\n",
    "                feature_obs = np.array([0.0 for i in range(n_features)])\n",
    "                # get relevance scores for observation, for explainers with only global scores, these will be used for every observation\n",
    "                if only_global:\n",
    "                    relevance_scores = list(explanations[explainer_name].global_relevance)\n",
    "                else:\n",
    "                    try:\n",
    "                        relevance_scores = list(explanations[explainer_name].pointwise_relevance.iloc[index_obs, :])\n",
    "                    except NonExistingRelevanceError:\n",
    "                        relevance_scores = list(explanations[explainer_name].global_relevance)\n",
    "\n",
    "                for feature_index in range(n_features):\n",
    "                    # get biggest score and column index (indicate which feature is meant) and pop from list\n",
    "                    index_biggest_score = relevance_scores.index(max(relevance_scores))                \n",
    "                    relevance_scores[index_biggest_score] = -100 # I set to large negative number as popping would ruin the index correspondence from relevance score to feature\n",
    "                    # get observation for this feature\n",
    "                    obs_biggest_score = X[index_obs, index_biggest_score]\n",
    "                    # get corresponding cluster index for this observation\n",
    "                    cluster_index = predictions[index_obs]\n",
    "                    # add observation for feature to feature observations list\n",
    "                    feature_obs.put(index_biggest_score, obs_biggest_score) # has to be at index of feature in training data, as otherwise distance calculation is wrong\n",
    "                    # impute other entries (length = num_features) --> TBD\n",
    "                    if use_imputer: \n",
    "                        if feature_index < (n_features - 1):\n",
    "                            feature_obs_imputed = imputer.predict(feature_obs, index_obs)\n",
    "                        else:\n",
    "                            feature_obs_imputed = feature_obs.copy()\n",
    "                    else:\n",
    "                        feature_obs_imputed = feature_obs.copy()\n",
    "                    # calculate distance to cluster centers for feature observations list\n",
    "                    distances = [np.linalg.norm(feature_obs_imputed - center) for center in cluster_centers]\n",
    "                    # get nearest_cluster_index\n",
    "                    nearest_cluster_index = distances.index(min(distances))\n",
    "                    # check whether cluster_index == nearest_cluster_index\n",
    "                    # if yes: return curve_obs_i\n",
    "                    # if no: replace first entry of curve_obs_i ith 0 and repeat\n",
    "                    if cluster_index == nearest_cluster_index:\n",
    "                        break\n",
    "                    else:\n",
    "                        curve_obs[feature_index] = 0\n",
    "                    # if yes: return curve_obs_i\n",
    "                    # if no: replace first entry of curve_obs_i ith 0 and repeat\n",
    "\n",
    "                curve_list.append(curve_obs)\n",
    "\n",
    "            # add explainer entry to dict\n",
    "            result_individual[explainer_name].extend(curve_list)\n",
    "\n",
    "    # Now compute AUC\n",
    "    result_auc = {explainer_name: (1 /(n_obs*n_features*n_trials)) * sum(map(sum, curves)) for explainer_name, curves in result_individual.items()}\n",
    "\n",
    "    dataset_results_global[dataset_name] = result_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1adc3b07-84e0-4e7d-8f78-dab7ea2137c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'iris': {'tree': 0.8236,\n",
       "  'forest': 0.9478500000000001,\n",
       "  'exkmc': 0.83345,\n",
       "  'gradient': 0.8055833333333333,\n",
       "  'shap': 0.9500166666666667,\n",
       "  'neon': 0.7864333333333333,\n",
       "  'xkm_next_best': 0.8693000000000001,\n",
       "  'xkm_all': 0.8738333333333334},\n",
       " 'wine': {'tree': 0.9340665514261021,\n",
       "  'forest': 0.9344252376836647,\n",
       "  'exkmc': 0.8932238547968886,\n",
       "  'gradient': 0.9037294727744166,\n",
       "  'shap': 0.9542480553154711,\n",
       "  'neon': 0.8846629213483147,\n",
       "  'xkm_next_best': 0.9262057044079517,\n",
       "  'xkm_all': 0.9194770959377702},\n",
       " 'wholesale': {'tree': 0.9453825757575758,\n",
       "  'forest': 0.949094696969697,\n",
       "  'exkmc': 0.9142954545454546,\n",
       "  'gradient': 0.8977537878787879,\n",
       "  'shap': 0.9658598484848485,\n",
       "  'neon': 0.9404431818181818,\n",
       "  'xkm_next_best': 0.9328371212121211,\n",
       "  'xkm_all': 0.9008863636363637},\n",
       " 'buddy': {'tree': 0.9016666666666666,\n",
       "  'forest': 0.9000401606425702,\n",
       "  'exkmc': 0.8949732262382865,\n",
       "  'gradient': 0.834665327978581,\n",
       "  'shap': 0.9195381526104417,\n",
       "  'neon': 0.8018942436412315,\n",
       "  'xkm_next_best': 0.8936144578313253,\n",
       "  'xkm_all': 0.8754685408299866},\n",
       " 'synthetic': {'tree': 0.628038,\n",
       "  'forest': 0.628142,\n",
       "  'exkmc': 0.6364799999999999,\n",
       "  'gradient': 0.632791,\n",
       "  'shap': 0.643888,\n",
       "  'neon': 0.62666,\n",
       "  'xkm_next_best': 0.632873,\n",
       "  'xkm_all': 0.635791},\n",
       " 'live_sellers': {'tree': 0.9458643026004728,\n",
       "  'forest': 0.9526808510638298,\n",
       "  'exkmc': 0.9456981875492514,\n",
       "  'gradient': 0.9307831363278173,\n",
       "  'shap': 0.9644605200945627,\n",
       "  'neon': 0.9272961386918834,\n",
       "  'xkm_next_best': 0.9396359338061466,\n",
       "  'xkm_all': 0.9006244286840032}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_results_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e0bdad2-6c9a-4e4d-b43c-0c245a1a4e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'iris': {'tree': 0.9509000000000001,\n",
       "  'forest': 0.9476333333333333,\n",
       "  'exkmc': 0.83525,\n",
       "  'gradient': 0.8339166666666668,\n",
       "  'shap': 0.9492166666666667,\n",
       "  'neon': 0.7506333333333334,\n",
       "  'xkm_next_best': 0.9458833333333334,\n",
       "  'xkm_all': 0.9469833333333334},\n",
       " 'wine': {'tree': 0.9325410544511669,\n",
       "  'forest': 0.9341961970613657,\n",
       "  'exkmc': 0.8928781331028522,\n",
       "  'gradient': 0.8707346585998272,\n",
       "  'shap': 0.9341356957649093,\n",
       "  'neon': 0.9075064822817632,\n",
       "  'xkm_next_best': 0.9160717372515126,\n",
       "  'xkm_all': 0.9243388072601556},\n",
       " 'wholesale': {'tree': 0.9486931818181817,\n",
       "  'forest': 0.9515227272727272,\n",
       "  'exkmc': 0.9152045454545454,\n",
       "  'gradient': 0.9032992424242424,\n",
       "  'shap': 0.9489431818181818,\n",
       "  'neon': 0.8920151515151515,\n",
       "  'xkm_next_best': 0.8744015151515151,\n",
       "  'xkm_all': 0.9153219696969697},\n",
       " 'buddy': {'tree': 0.893768406961178,\n",
       "  'forest': 0.9020214190093708,\n",
       "  'exkmc': 0.895863453815261,\n",
       "  'gradient': 0.837764390896921,\n",
       "  'shap': 0.900475234270415,\n",
       "  'neon': 0.8023360107095047,\n",
       "  'xkm_next_best': 0.9008902275769746,\n",
       "  'xkm_all': 0.8993038821954484},\n",
       " 'synthetic': {'tree': 0.628201,\n",
       "  'forest': 0.628128,\n",
       "  'exkmc': 0.63686,\n",
       "  'gradient': 0.6375879999999999,\n",
       "  'shap': 0.6279239999999999,\n",
       "  'neon': 0.637056,\n",
       "  'xkm_next_best': 0.628004,\n",
       "  'xkm_all': 0.6373179999999999},\n",
       " 'live_sellers': {'tree': 0.9457973207249804,\n",
       "  'forest': 0.9525380614657211,\n",
       "  'exkmc': 0.9456598896769111,\n",
       "  'gradient': 0.8710299448384555,\n",
       "  'shap': 0.9524756501182033,\n",
       "  'neon': 0.8853431048069347,\n",
       "  'xkm_next_best': 0.9419648542159181,\n",
       "  'xkm_all': 0.9425101654846336}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_results_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c99a2ca4-f9ae-47e3-abf4-1a02c2afc232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serializing json\n",
    "import json\n",
    "json_local_results = json.dumps(dataset_results_local, indent=4)\n",
    " \n",
    "# Writing to sample.json\n",
    "with open(\"results_local.json\", \"w\") as outfile:\n",
    "    outfile.write(json_local_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80c34a97-d3b3-40a5-822c-2a9d90b2ae54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serializing json\n",
    "json_global_results = json.dumps(dataset_results_global, indent=4)\n",
    " \n",
    "# Writing to sample.json\n",
    "with open(\"results_global.json\", \"w\") as outfile:\n",
    "    outfile.write(json_global_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cxplain",
   "language": "python",
   "name": "cxplain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
